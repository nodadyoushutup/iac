# AGENTS

## Secrets & variable locations
- Jenkins agent/controller secrets, CASC fragments, and SSH materials live under `~/.jenkins`. The Jenkins Terraform stages (`terraform/swarm/jenkins/**`) and their pipelines read from this directory, so keep credentials and token files synced before running controller/agent/config deployments.
- Terraform inputs live under `~/.tfvars`. Each Swarm stack defaults to `~/.tfvars/<service>.tfvars` (Dozzle, Graphite, Node Exporter, Prometheus) unless the pipeline overrides `DEFAULT_TFVARS_FILE`. Grafana and Jenkins use subfolders with stage-specific files (`~/.tfvars/grafana/app.tfvars`, `config.tfvars`; `~/.tfvars/jenkins/controller.tfvars`, `agent.tfvars`, `config.tfvars`). Legacy non-Swarm stacks (ArgoCD, Proxmox, Talos, etc.) follow the same naming scheme when re-enabled.
- All Swarm stacks use the MinIO backend declared in `~/.tfvars/minio.backend.hcl`. Pipelines pass this file to `terraform init -backend-config` automatically, but you can override it with `--backend`.
- When introducing a new service or stage, you (Codex) are responsible for creating or updating the matching tfvars/backend files under `~/.tfvars`. Start by opening the closest existing tfvars/backends (for example, `~/.tfvars/prometheus.tfvars`, `~/.tfvars/grafana/app.tfvars`) so the new files mirror the established structure. Capture the filenames, backend keys, and any placeholders in the planning doc before coding, then actually write the files (or refreshed values) under `~/.tfvars` so pipelines can run without extra user steps. When secrets are unknown, stub the structure and call out the missing values in both the tfvars file and the plan, but never defer file creation to the user. Stage 0 of the plan must also include a verification task (for example, `ls ~/.tfvars/<service>.tfvars`) so we prove the files exist before moving on.

## Application taxonomy & pipeline expectations
- **App + config** – services that deploy infrastructure and then push additional configuration once the app is reachable (Jenkins controller/agents + config, Grafana app + provider-driven dashboards). These require multiple Terraform surfaces (usually `module/<service>/app` + `module/<service>/config`) and at least two pipelines (`pipeline/<service>/app.*`, `pipeline/<service>/config.*`). Jenkins is the special case with three stages (controller, agent, config) because agents depend on controller outputs.
- **App w/ inline config** – services where configuration is rendered as part of the same Terraform module (Prometheus uses tfvars data to produce the scrape/rules YAML). Pipelines still target the `app` stage but there is no second apply.
- **App only** – single-shot services that embed all behavior in one module (Dozzle, Node Exporter, Graphite). They ship a single pipeline/jenkins pair named `deploy`.
- **Config only (future)** – reserved for stacks that only change configuration for an existing app (for example, an Argo CD workload update). Keep this documented so future contributors add the missing automation layers.
- **Pattern reuse rule** – start from the closest implementation before diverging. Clone Jenkins if you need multi-stage Swarm + Jenkins provider work, Grafana for dual-provider app+config flows, Prometheus for inline-config services, and Dozzle/Graphite for single-stage Swarm apps. Document any deviation inside the planning doc.
- **Provider availability check** – part of picking a taxonomy is confirming whether a first-class Terraform provider exists for the service. Favor the established provider (official or widely adopted community plugin) before writing ad-hoc Docker resources, and cite that decision in Stage 0 of the plan.

## Major feature workflow (all services)
1. **Scope & triggers** – Before touching code, confirm the taxonomy, list the directories you expect to touch (`terraform/module/<service>`, `terraform/swarm/<service>` or `terraform/swarm/<service>/<stage>`, `pipeline/<service>`, relevant `docker/<service>` assets, Jenkins job definitions), and note the tfvars/backend files under `~/.tfvars` that will feed the change. Part of scoping is verifying whether a well-supported Terraform provider (official or the community-standard one) already exists for the service; document the provider name/link or call out that you must build native resources before continuing.
2. **Create a multi-stage plan document** – Store it at `docs/planning/<service>-plan.md`. Capture the goal/constraints plus numbered Stage sections (Stage 0 – Preparation, Stage 1 – Implementation, etc.) with checkbox tasks (`- [ ]`) spelling out Terraform, pipeline, Jenkins, tfvars, and documentation work. Stage 0 must explicitly list (a) every tfvars/backend path the change requires with a checkbox to confirm the file exists/was created, (b) the reference implementation(s) we are cloning, and (c) the pipeline + Jenkins surfaces that must be added or updated. Later stages should trace each repo touchpoint (modules, pipelines, Jenkins job registry, docs, resource catalog entries, wiki pages, node-label docs) back to those checkboxes so reviewers can see what is left. Call out which prior implementation you are cloning and why before moving to Stage 1, and include sanitized tfvars/backend snippets plus the commands (`ls`, `cat`, etc.) you will run to prove they exist so we do not need to rebuild the plan later.
3. **Execute stage-by-stage** – Follow the plan order, updating checkboxes as tasks/stages finish. If scope drifts, append a note to the plan before continuing so the history stays accurate.
4. **Validation & wrap-up** – Record which bash/Jenkins pipelines ran, their outcomes, any pending Terraform applies, and the command/output that proves the tfvars/backend files exist (for example, `ls ~/.tfvars && cat ~/.tfvars/<service>.tfvars`). Split every validation checklist into **Agent tests** (commands Codex can run autonomously) and **Human tests** (manual verification the operator must perform) so responsibilities stay obvious. Link the new automation (pipelines, Terraform dirs, docs) and the Jenkins job names from that plan so future operators can trace provenance.

The planning document’s checklist remains the readiness gate for Swarm work—finish it before merging.

## Repository surfaces per Swarm service
- **Modules (`terraform/module/<service>`)** – contain the actual Docker resources. Multi-stage services split into `module/<service>/app` and `module/<service>/config` (Grafana) or further granularity (`module/jenkins/{controller,agent}` plus `module/jenkins/config`). Modules hold all static defaults (image digests, labels, networks, health checks) expressed via locals so tfvars stay minimal.
- **Stack entrypoints (`terraform/swarm/<service>`)** – wire Terraform backends, providers, and module invocations. Single-state services (Dozzle, Prometheus, Graphite, Node Exporter) live directly under `terraform/swarm/<service>`. Multi-stage stacks (Grafana app/config, Jenkins controller/agent/config) keep stage-specific Terraform dirs (for example, `terraform/swarm/grafana/{app,config}` and `terraform/swarm/jenkins/{controller,agent,config}`) so each state stays focused.
- **Pipelines (`pipeline/<service>/<stage>.sh`)** – bash entrypoints that set `SERVICE_NAME`, `STAGE_NAME`, and any overrides (for example, `PLAN_ARGS_EXTRA` to `-target` a module or custom `TERRAFORM_DIR`) before sourcing `pipeline/script/swarm_pipeline.sh`. One directory per service keeps app/config/deploy scripts co-located. When adding a pipeline, open the closest existing service stage first (for example, reuse Grafana app/config for two-stage services or Dozzle for single-stage ones) and note that reference inside Stage 0 of the plan. Stage 2 of the plan must have explicit checkboxes for the new `.sh` file, its `.jenkins` sibling, default tfvars/backends, and the Jenkins job registry update so nothing is skipped.
- **Jenkins wrappers (`pipeline/<service>/<stage>.jenkins`)** – declarative pipelines that parameterize and call the matching bash script through `runShellPipeline`. Every bash script must have a Jenkins counterpart so CI/CD and local workflows stay in sync. Stage 2 of the planning doc must call out the exact Jenkins wrapper filename(s) being added/modified and include a checkbox to confirm they were created and committed alongside the shell script.
- **Jenkins job registry (`terraform/module/jenkins/config`)** – the Terraform module that creates Jenkins folders/jobs. Add new services to `local.single_stage_jobs` or `local.multi_stage_services` so jobs are provisioned as soon as the stack merges. The planning doc must list the exact locals you expect to touch and include a checkbox to confirm the registry change landed before marking the stage complete.
- **Pipeline helpers (`pipeline/script/`)** – shared tooling (`env_check.sh`, `resolve_inputs.sh`, `swarm_pipeline.sh`, `terraform_exec.sh`, `terraform_output_filter.py`) that every stage sources. Keep new helpers here so all services inherit them automatically.
- **Planning docs (`docs/planning/<service>-plan.md`)** – capture scope, reference implementations, validation notes, and outstanding work. They are the source of truth for stage readiness.

## TFVARS, provider_config, and backend contract
- The helper `pipeline/script/resolve_inputs.sh` looks for tfvars/backends in order: CLI flags (`--tfvars`, `--backend`), script overrides (`DEFAULT_TFVARS_FILE`, `DEFAULT_BACKEND_FILE`), then `~/.tfvars/<basename>.tfvars`. Always document the intended filenames and keep them under `~/.tfvars`.
- Before writing a new tfvars/backend, diff it against the closest existing service so the key names, nested maps, and provider_config structure match what Terraform expects. Paste a sanitized snippet (minus secrets) into Stage 0/1 of the planning doc and state whether the file already existed or was created during the work so reviewers can audit the structure without logging into your shell.
- Every Swarm stack expects a `provider_config` map with at least the Docker host definition (`docker.host` + `docker.ssh_opts`). Add nested provider blocks only when necessary (for example, `provider_config.grafana` for Grafana auth, `provider_config.jenkins` for Jenkins username/password/API token). Keep secrets in tfvars, never in the repo.
- Configuration-heavy services keep their structured inputs in tfvars as well (`casc_config`, Grafana `datasources`/`dashboards`, `prometheus_config`, Jenkins mounts/env maps). Modules render these maps into YAML/JSON or Docker configs internally so the repo only carries module logic.
- **tfvars hygiene** – Only promote values to tfvars when they are secrets, environment-specific coordinates, or explicitly called out in the plan. Prefer Terraform locals/constants for static behavior to avoid chasing dozens of inputs, and document in Stage 0 which values stay in tfvars versus which will be encoded as locals so reviewers can spot scope creep early.
- All Swarm stacks share the MinIO backend (`~/.tfvars/minio.backend.hcl`). Unless a plan explicitly calls for something else, leave the backend key naming consistent (`<service>.tfstate`, `jenkins-<stage>.tfstate`) and let the pipeline pass the backend file automatically.

## Docker Swarm module conventions
- Keep resources prefixed with the service name (`grafana`, `prometheus`, `jenkins-controller`, etc.) and always set `com.docker.stack.namespace` + `com.docker.service` labels so Swarm dashboards stay coherent.
- Encode all static defaults directly in the module via locals: container images/digests, environment defaults, health checks, published ports, placement constraints, and external network attachments (`module/grafana/app` shows the Prometheus network attach pattern).
- Split multi-phase services into explicit modules: `module/grafana/{app,config}`, `module/jenkins/{controller,agent}` + `module/jenkins/config`. Single-phase services keep a single `main.tf`.
- When an app consumes YAML or JSON config (Prometheus scrape config, Grafana dashboards/datasources, Jenkins CASC), accept structured maps in tfvars and render them inside the module with `yamlencode`/`jsonencode` + `docker_config` resources.
- Reuse support modules such as `module/healthcheck` instead of re-implementing polling logic whenever an HTTP health probe is needed outside the container.

## Pipeline implementation details
- Each bash entrypoint under `pipeline/<service>/` defines `SERVICE_NAME`, `STAGE_NAME`, optional overrides (`ENTRYPOINT_RELATIVE`, `TERRAFORM_DIR`, `DEFAULT_TFVARS_FILE`, `PLAN_ARGS_EXTRA`, `APPLY_ARGS_EXTRA`) and then sources `pipeline/script/swarm_pipeline.sh`. Arguments passed to the bash script are forwarded through `PIPELINE_ARGS`.
- `swarm_pipeline.sh` handles `--tfvars`/`--backend` flags, runs the shared helpers (`env_check.sh`, `resolve_inputs.sh`, `terraform_exec.sh`), and performs `terraform init`, `plan`, and `apply`. Output filtering runs through `pipeline/script/terraform_output_filter.py` when Python is available.
- Use `PLAN_ARGS_EXTRA` / `APPLY_ARGS_EXTRA` only when you must scope a stage to part of a Terraform tree. Prefer setting `TERRAFORM_DIR` so each stage has its own state (Grafana app/config and all Jenkins stages follow this pattern now).
- Implement `pipeline_pre_terraform()` inside a stage script when you must prepare data before init/plan. Example: `pipeline/jenkins/agent.sh` initializes the controller backend and exports `TF_VAR_controller_service_id` / `TF_VAR_controller_image` before sourcing `swarm_pipeline.sh`.
- Every bash script has a `.jenkins` sibling that uses the shared `runShellPipeline` helper to execute the shell script inside Jenkins. Always keep the Jenkins script name in sync with the bash entrypoint path exposed through Terraform (`terraform/module/jenkins/config`).
- Close Stage 2 in the planning doc only after you have (a) documented which existing pipeline you cloned, (b) confirmed the `.sh` and `.jenkins` files are both committed, (c) updated `terraform/module/jenkins/config`, and (d) noted which tfvars/backends the pipeline expects. Write those confirmations directly into the checklist so reviewers can trace evidence without asking.

## Jenkins job automation
- `terraform/module/jenkins/config/main.tf` provisions folders/jobs using the `taiidani/jenkins` provider. Update the locals there whenever a pipeline changes:
  - Add app-only services (Dozzle, Node Exporter, Graphite, Prometheus deploy) to `local.single_stage_jobs`.
  - Add multi-stage services to `local.multi_stage_services`, listing each stage name + script path so Terraform creates the folder and jobs (Grafana currently uses app/config).
  - Keep Jenkins controller/agent/config jobs listed in `local.jenkins_jobs`; treat them as the canonical reference for multi-stage patterns.
- New jobs must point at the `pipeline/<service>/<stage>.jenkins` script path and include a short description explaining what the stage deploys. The Jenkins provider template will take care of the rest.

## Docker Swarm service workflow
- **Stage 0 – Baseline**: Document the reference implementation you are cloning (Jenkins, Grafana, Prometheus, Dozzle/Graphite) in the plan. Capture all touchpoints you will need: `terraform/module/<service>` scaffolding, `terraform/swarm/<service>` or per-stage subdirectories, pipeline entrypoints, Jenkins jobs, tfvars/backends, docs, resource catalog updates, and any supporting Docker assets. Explicitly note the tfvars filenames and backend key you expect to use, add checkboxes to record whether each file already exists or must be created, and list the commands you will run (`ls`, `cat`, `tee`, etc.) to prove those files exist later. Record the taxonomy decision, provider version(s) + documentation links, and any node-label strategy (including the `docker node update` commands you intend to publish) so reviewers agree on placement before coding. Call out which inputs remain in tfvars (typically secrets or environment-specific coordinates) versus which will be baked into Terraform locals to keep subsequent stages aligned. This stage must also verify whether a Terraform provider already covers the service (and link to it) or state why you are building the resources by hand so reviewers know the taxonomy choice is justified.
- **Stage 1 – Terraform scaffolding**: Build or extend `terraform/module/<service>` (and `app`/`config` submodules when needed) plus the matching `terraform/swarm/<service>` stack. Keep provider wiring aligned with `provider_config` inputs and reference the `~/.tfvars/minio.backend.hcl` backend. Export outputs that downstream stages might need (for example, Jenkins controller service ID/image). If this stage adds a new provider or container image, add it to the Resource links section and drop the link/version into the plan checklist so reviewers can see the provenance.
- **Stage 2 – Pipelines**: Create `pipeline/<service>/<stage>.sh` and `.jenkins` files. Set `DEFAULT_TFVARS_BASENAME`/`DEFAULT_TFVARS_FILE`, `STAGE_NAME`, and `PLAN/APPLY` targets so the shared `swarm_pipeline.sh` helper can run unattended. Document any stage-specific environment requirements (`pipeline_pre_terraform`) inside both the script comments and the planning doc. The plan must point at the template you cloned, include checkboxes for the `.sh` + `.jenkins` pair, the Jenkins job registry entry, and the tfvars/backends that the pipeline consumes.
- **Stage 3 – Jenkins integration & configs**: For app + config or inline config services, ensure both stages are registered in `terraform/module/jenkins/config` and that tfvars files contain the secrets/config needed. For app-only services, add the single job entry and double-check Jenkins credentials in `~/.jenkins` still match the provider block. Stage 3 of the plan must show the exact locals you updated, the Jenkins job names that were created, and the verification command/output (for example, `terraform plan` diff or `git show`) that proves the registry now references the new pipelines.
- **Stage 4 – Validation & docs**: Run the bash pipelines (and Jenkins jobs when possible), record the command/output location plus backend state in the planning doc, and update wiki/runbooks with any new operational steps. Every Stage 4 section must explicitly break out **Agent tests** versus **Human tests** (for example, “Agent – run `pipeline/... --plan`” vs “Human – hit the public URL and verify TLS”). Capture which persona performed each test, keep the commands/results in the plan, and leave a note if applies were deferred or require credentials beyond the repo.

## Resource links
- Whenever you add a new Terraform provider or container image to this repo, update the list below (or add a new subsection) in the same commit so future work has a vetted reference. Mention the version/documentation URL you relied on in the planning doc and cross-link it here for quick lookup.
- **Terraform providers**
  - [`kreuzwerker/docker`](https://registry.terraform.io/providers/kreuzwerker/docker/latest/docs) – used by every Swarm stack under `terraform/swarm/*` and the corresponding modules.
  - [`grafana/grafana`](https://registry.terraform.io/providers/grafana/grafana/latest/docs) – powers `terraform/module/grafana/config` for dashboards, folders, and datasources.
  - [`taiidani/jenkins`](https://registry.terraform.io/providers/taiidani/jenkins/latest/docs) – manages `terraform/module/jenkins/config` (folders/jobs) and Jenkins-aware stacks.
- **Container images**
  - [`amir20/dozzle`](https://github.com/amir20/dozzle) – referenced in `terraform/module/dozzle`.
  - [`prom/node-exporter`](https://hub.docker.com/r/prom/node-exporter) – referenced in `terraform/module/node_exporter`.
  - [`prom/prometheus`](https://hub.docker.com/r/prom/prometheus) – referenced in `terraform/module/prometheus`.
  - [`grafana/grafana`](https://hub.docker.com/r/grafana/grafana) – referenced in `terraform/module/grafana/app`.
  - [`graphiteapp/graphite-statsd`](https://hub.docker.com/r/graphiteapp/graphite-statsd) – referenced in `terraform/module/graphite`.
  - [`minio/minio`](https://min.io/docs/minio/container/index.html) – defined via `docker/minio/docker-compose.yaml` for the Terraform backend.
  - [`ghcr.io/nodadyoushutup/jenkins-controller`](docker/jenkins/controller) – custom controller image built from `docker/jenkins/controller/`.
  - [`ghcr.io/nodadyoushutup/jenkins-agent`](docker/jenkins/agent) – custom agent image built from `docker/jenkins/agent/`.

> Finish the staged plan in `docs/planning` before merging—its checklist is the single source of truth for Swarm readiness.
